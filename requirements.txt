fastapi>=0.109.2
uvicorn>=0.27.1
pydantic>=2.6.1
pydantic-settings>=2.2.1
aiogram>=3.3.0
youtube-transcript-api>=1.2.4
sentence-transformers>=2.3.1
faiss-cpu>=1.7.4
langchain>=0.1.5
langchain-groq>=0.0.1
langchain-text-splitters>=0.2.0
tiktoken>=0.7.0
redis>=5.0.1
celery>=5.3.6
python-dotenv>=1.0.1
pytest>=8.0.0
pytest-asyncio>=0.23.5
httpx>=0.26.0
sqlalchemy>=2.0.25
asyncpg>=0.29.0

# force CPU-only PyTorch to keep wheel size manageable and avoid CUDA packages which are huge
# sentence-transformers pulls in torch; pinning here ensures the docker build fetches the smaller CPU wheel
--extra-index-url https://download.pytorch.org/whl/cpu
torch==2.10.0+cpu
